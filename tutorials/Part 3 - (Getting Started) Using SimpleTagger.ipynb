{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started: SimpleTagger\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will learn about how to use the `SimpleTagger` pipeline component that enables token level\n",
    "tagging with custom attributes and custom labels. Today we'll focus on tagging `stop words` and english articles\n",
    "as definite or indefinite to showcase the different setups available for the tagger. The same component could\n",
    "be used for token level polarity tagging or simple forms of NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Antonio Lopardo`  -> [@AntonioLprd](https://twitter.com/AntonioLprd) (Twitter)\n",
    "\n",
    "## 1. Torch hooking and worker setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by hooking torch with PySyft to add additional functionalities and we create a local worker that will be\n",
    "the owner of the pipeline in which we will run the tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import spacy #<- We use spacy just to import a list of stop words\n",
    "\n",
    "import syft as sy\n",
    "\n",
    "import syfertext\n",
    "from syfertext.pipeline import SimpleTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "# Create a torch hook for PySyft\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "# Create a PySyft workers\n",
    "me = hook.local_worker #<- This is the worker from which we manage the processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Creating a stop-word tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Loading farly extensive list of stop words from one of spacy's models\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "stopwords = sp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `SimpleTagger` can be initialized in two ways. We can pass in the lookups argument a `set` of tokens that\n",
    "should be labeled with the object in the `tag` field and so letting every other token not included in `set`\n",
    "in `lookups` be labeled with the `default_tag`. Or `lookups` can be a `dict` where the keys are tokens and the\n",
    "values are their respective tags for the attribute that we would like to add with the tagger. In this second\n",
    "case the `default_tag` can also be used for tokens not in the `dict`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's initialize our `stop_tagger` with the set of stop-words from spacy\n",
    "* `attribute` helps us name the custom attribute we are creating\n",
    "* `lookups` in this case is a set of tokens\n",
    "* `tag` the object with which to tag the tokens in the `lookups` set\n",
    "* `default_tag` the object with which to tag tokens not in `lookups` set\n",
    "* `case_sensitive` a boolean flag that indicates if capitalization should be considered when matching tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stop_tagger = SimpleTagger(attribute = 'is_stop',\n",
    "                           lookups = stopwords,\n",
    "                           tag = True,\n",
    "                           default_tag = False,\n",
    "                           case_sensitive = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Creating a tagger for article type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's initialize our `article_tagger` with a `dict` with tokens as keys and tags for the attribute as values\n",
    "* `attribute` helps us name the custom attribute we are creating\n",
    "* `lookups` in this case it is a dictionary\n",
    "* `default_tag` the object with which to tag tokens not in the `lookups` dict\n",
    "* `case_sensitive` a boolean flag that indicates if capitalization should be considered when matching tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#define the tags for our dictionary\n",
    "definite = \"definite\"\n",
    "indefinite = \"indefinite\"\n",
    "\n",
    "#Initializing the dict to feed to the SimpleTagger constructor \n",
    "articles_dict = {\"the\": definite, \"a\": indefinite, \"an\": indefinite}\n",
    "\n",
    "article_tagger = SimpleTagger(attribute = 'is_article',\n",
    "                           lookups = articles_dict,\n",
    "                           default_tag = False,\n",
    "                           case_sensitive = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline integration\n",
    "Using the add_pipe method it is easy to integrate the new tagger in our nlp pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Language' object has no attribute 'add_pipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ae2a1fc3eca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyfertext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_lg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m nlp.add_pipe(name = 'stop tagger',#<- We add the stop tagger to the pipeline with a distinctive name\n\u001b[0m\u001b[1;32m      5\u001b[0m                  \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop_tagger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                  \u001b[0mremote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Language' object has no attribute 'add_pipe'"
     ]
    }
   ],
   "source": [
    "#Initialize an nlp pipeline that by default contains a tokenizer.\n",
    "nlp = syfertext.load(\"en_core_web_lg\", owner= me) \n",
    "\n",
    "nlp.add_pipe(name = 'stop tagger',#<- We add the stop tagger to the pipeline with a distinctive name\n",
    "                 component = stop_tagger,\n",
    "                 remote = True\n",
    "                )\n",
    "\n",
    "nlp.add_pipe(name= 'article tagger', #<- We add the article tagger to the pipeline with a distinctive name\n",
    "             component= article_tagger,\n",
    "             remote= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_string = \"thereafter a various group of the people left\"\n",
    "\n",
    "#apply in sequence tokenizer->stop_tagger->article_tagger\n",
    "tagged_test_string = nlp(test_string)\n",
    "\n",
    "for token in tagged_test_string: #<-If the data on which we operate is local we can access the custom attribute using \"._.\"\n",
    "    print('%10s | %5s | %s'%(token, token._.is_stop, token._.is_article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## And we are done!👍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of `SimpleTagger` now you should be able to tackle most token-level \n",
    "tagging task when using SyferText."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have any questions or suggestions, you can find us on OpenMined's [slack channel](http://slack.openmined.org/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
