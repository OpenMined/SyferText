{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# How to use: Simple Tagger\n",
    "----------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial, you will learn about how to use the `SimpleTagger` pipeline component that enables token level\n",
    "tagging with custom attributes and custom labels. Today we'll focus on tagging `stop words` and english articles\n",
    "as definite or indefinite to showcase the different setups available for the tagger. The same component could\n",
    "be used for token level polarity tagging or simple forms of NER."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Author\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- `Antonio Lopardo`  -> [@AntonioLprd](https://twitter.com/AntonioLprd) (Twitter)\n",
    "\n",
    "## Torch hooking and worker setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by hooking torch with PySyft to add additional functionalities and we create a local worker that will be\n",
    "the owner of the pipeline in which the tagger will be integrated."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy #<_ We use spacy just for a list of stop words\n",
    "\n",
    "import syft as sy\n",
    "from syft.generic.string import String #<- We import it to convert generic strings to PySyft strings\n",
    "\n",
    "import syfertext\n",
    "from syfertext.pipeline import SimpleTagger"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "# Create a torch hook for PySyft\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "# Create a PySyft workers\n",
    "me = hook.local_worker #<- This is the worker from which the processing is managed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## StopwordsTagger setup using spacy for a set of stop words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#Loading farly extensive list of stop words from one of spacy's models\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "stopwords = sp.Defaults.stop_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's initialize our `stop_tagger`\n",
    "`attribute` helps us name the custom attribute we are creating\n",
    "`lookups` in this case is a set of tokens that should be tagged with the object in the `tag` field\n",
    "`tag` the object with which to tag the tokens in the `lookups` set\n",
    "`default_tag` the object with which to tag tokens not in `the lookups` set\n",
    "`case_sensitive` a boolean flag that indicates if capitalization should be considered when matching tokens in the ones in lookups"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "stop_tagger = SimpleTagger(attribute = 'is_stop',\n",
    "                           lookups = stopwords,\n",
    "                           tag = True,\n",
    "                           default_tag = False,\n",
    "                           case_sensitive = False\n",
    "                          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ArticleTagger setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also send a `dict` to `lookups` specifing for the tokens included an object with which to tag them\n",
    "`attribute` helps us name the custom attribute we are creating\n",
    "`lookups` in this case is a dict with tokens as keys and objects with which to tag them as values\n",
    "`tag` ignored\n",
    "`default_tag` the object with which to tag tokens not in the `lookups` dict\n",
    "`case_sensitive` a boolean flag that indicates if capitalization should be considered when matching tokens in the ones in lookups\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#Converting \"definite\" and \"indefinite\" to PySyft Strings\n",
    "definite = String(\"definite\")\n",
    "indefinite = String(\"indefinite\")\n",
    "\n",
    "#Initializing the dict to feed to the SimpleTagger constructor \n",
    "articles_dict = {\"the\": definite, \"a\": indefinite, \"an\": indefinite}\n",
    "\n",
    "article_tagger = SimpleTagger(attribute = 'is_article',\n",
    "                           lookups = articles_dict,\n",
    "                           tag = None,\n",
    "                           default_tag = False,\n",
    "                           case_sensitive = False\n",
    "                          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipeline integration\n",
    "Using the add_pipe method it is easy to integrate the new tagger in our nlp pipeline."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#Initialize an nlp pipeline that by default contains a tokenizer.\n",
    "nlp = syfertext.load(\"en_core_web_lg\", owner= me) \n",
    "\n",
    "nlp.add_pipe(name = 'stop tagger',#<- We add the stop tagger to the pipeline with a distinctive name\n",
    "                 component = stop_tagger,\n",
    "                 remote = True\n",
    "                )\n",
    "\n",
    "nlp.add_pipe(name= 'article tagger', #<- We add the article tagger to the pipeline with a distinctive name\n",
    "             component= article_tagger,\n",
    "             remote= True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thereafter |  True | False\n",
      "         a |  True | indefinite\n",
      "   various |  True | False\n",
      "     group | False | False\n",
      "        of |  True | False\n",
      "       the |  True | definite\n",
      "    people | False | False\n",
      "      left | False | False\n"
     ]
    }
   ],
   "source": [
    "test_string = String(\"thereafter a various group of the people left\")\n",
    "\n",
    "#apply in sequence tokenizer->stop_tagger->article_tagger\n",
    "tagged_test_string = nlp(test_string)\n",
    "\n",
    "for token in tagged_test_string: #<-If the data on which we operate is local we can access the custom attribute using \"._.\"\n",
    "    print('%10s | %5s | %s'%(token, token._.is_stop, token._.is_article))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}