{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H3RxK_9yHTAs"
   },
   "source": [
    "# Getting Started: SimpleTagger\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VJmSv8vHTAu"
   },
   "source": [
    "In this tutorial, you will learn about how to use the `SimpleTagger` pipeline component that enables token level\n",
    "tagging with custom attributes and custom labels. Today we'll focus on tagging `stop words` and english articles\n",
    "as definite or indefinite to showcase the different setups available for the tagger. The same component could\n",
    "be used for token level polarity tagging or simple forms of NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMpPFm2KHTAw"
   },
   "source": [
    "#### Author\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMAOkGH5HTAx"
   },
   "source": [
    "- `Antonio Lopardo`  -> [@AntonioLprd](https://twitter.com/AntonioLprd) (Twitter)\n",
    "\n",
    "## 1. Torch hooking and worker setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoTdXqWgHTAz"
   },
   "source": [
    "We start by hooking torch with PySyft to add additional functionalities and we create a local worker that will be\n",
    "the owner of the pipeline in which we will run the tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "4H6hIEPQHTA1",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "e9bbd9ac-53ea-4c74-c2ab-6baf0330efa6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n",
      "WARNING:root:Torch was already hooked... skipping hooking process\n",
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import syft as sy\n",
    "\n",
    "import syfertext\n",
    "from syfertext.pipeline import SimpleTagger\n",
    "from syfertext.local_pipeline import get_test_language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "lByoaeU5HTBA",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "58a9f4c0-2073-4231-da63-9d16646f3bce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "# Create a torch hook for PySyft\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "# Create a PySyft workers\n",
    "me = hook.local_worker #<- This is the worker from which we manage the processing\n",
    "me.is_client_worker = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzusEyvsHTBG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Creating a stop-word tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "MQkJY8poHTBI",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Initialize a farly extensive list of stop words from https://meta.wikimedia.org/wiki/Stop_word_list/google_stop_word_list#English\n",
    "\n",
    "stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \n",
    "             \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \n",
    "             \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \n",
    "             \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn't\",\n",
    "             \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
    "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \n",
    "             \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \n",
    "             \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \n",
    "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\",\n",
    "             \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\",\n",
    "             \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\",\n",
    "             \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\",\n",
    "             \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\",\n",
    "             \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\",\n",
    "             \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "             \"your\" \"yours\" \"yourself\" \"yourselves\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RoJzcFNHTBN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `SimpleTagger` can be initialized in two ways. \n",
    "1. With the `lookups` argument as a `set`\n",
    "2. With the `lookups` argument as a `dict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3fBDtinHTBP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's initialize our `stop_tagger` with the set of stop-words we initialized\n",
    "* **attribute**: name of the attribute to add to the tokens\n",
    "* **lookups**: a `set` of tokens to be labeled with `tag`\n",
    "* **tag**: the object with which to tag the tokens in the `lookups` set\n",
    "* **default_tag**: the object with which to tag tokens not in `lookups` set\n",
    "* **case_sensitive**: a boolean flag that indicates if capitalization should be considered when matching tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "nfxCPdK1HTBP",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stop_tagger = SimpleTagger(attribute = 'is_stop',\n",
    "                           lookups = stopwords,\n",
    "                           tag = True,\n",
    "                           default_tag = False,\n",
    "                           case_sensitive = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMqn8ZR5HTBV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Creating a tagger for article type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1Y0eGPCHTBW"
   },
   "source": [
    "Now let's initialize our `article_tagger` with a `dict` with tokens as keys and tags for the attribute as values\n",
    "* **attribute**: name of the attribute to add to the tokens\n",
    "* **lookups**: a `dict` where keys are tokens and the values are the objects with which to label them\n",
    "* **tag**: not needed if `lookups` is a dict since the dict itself contains the tag objects\n",
    "* **default_tag**: the object with which to tag tokens not in the `lookups` dict\n",
    "* **case_sensitive**: a boolean flag that indicates if capitalization should be considered when matching tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Pbrm80VAHTBY",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#define the tags for our dictionary\n",
    "definite = \"definite\"\n",
    "indefinite = \"indefinite\"\n",
    "\n",
    "#Initializing the dict to feed to the SimpleTagger constructor \n",
    "articles_dict = {\"the\": definite, \"a\": indefinite, \"an\": indefinite}\n",
    "\n",
    "article_tagger = SimpleTagger(attribute = 'is_article',\n",
    "                           lookups = articles_dict,\n",
    "                           default_tag = False,\n",
    "                           case_sensitive = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQAcxbUxHTBc"
   },
   "source": [
    "## 4. Pipeline integration\n",
    "Using the add_pipe method it is easy to integrate the new tagger in our nlp pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "aPbEnz3gHTBd",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Initialize an nlp pipeline that by default contains a tokenizer.\n",
    "nlp = get_test_language_model()\n",
    "\n",
    "#We add the stop tagger to the pipeline with a distinctive name\n",
    "nlp.add_pipe(name = 'stop tagger',\n",
    "                 component = stop_tagger,\n",
    "                 access = {'*'}\n",
    "                )\n",
    "\n",
    "#We add the article tagger to the pipeline with a distinctive name\n",
    "nlp.add_pipe(name= 'article tagger', \n",
    "             component= article_tagger,\n",
    "             access = {'*'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Hkg4dq0NHTBh",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "d64cad84-261f-4965-b41f-22a2e34168f8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thereafter | False | False\n",
      "         a |  True | indefinite\n",
      "   various | False | False\n",
      "     group | False | False\n",
      "        of |  True | False\n",
      "       the |  True | definite\n",
      "    people | False | False\n",
      "      left | False | False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nilansh/Anton/OpenMined/PySyft/syft/frameworks/torch/hook/hook.py:560: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_string = \"thereafter a various group of the people left\"\n",
    "\n",
    "#apply in sequence tokenizer->stop_tagger->article_tagger\n",
    "tagged_test_string = nlp(test_string)\n",
    "\n",
    "#If the data on which we operate is local we can access the custom attribute using \"._.\"\n",
    "for token in tagged_test_string: \n",
    "    print('%10s | %5s | %s'%(token, token._.is_stop, token._.is_article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22SMX-PnHTBn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## And we are done!👍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXRyoya5HTBn"
   },
   "source": [
    "With the help of `SimpleTagger` now you should be able to tackle most token-level \n",
    "tagging tasks when using SyferText."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qiXqPiTHTBo"
   },
   "source": [
    "If you have any questions or suggestions, you can find us on OpenMined's [slack channel](http://slack.openmined.org/)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Part 3 - (Getting Started) Using SimpleTagger.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
